\section{Safety, Trust, and Deployment Constraints}
\label{sec:safety}

Safety is a huge topic regarding the use of AI in any system that may endanger lives.
And hallucinations are a huge issue. I will be looking into more papers in this direction.
At work we had huge problems with our customer because the realtime speech models hallucinate on the very extreme end.
Several times they were making things up regarding our customersâ€™ data.
Ours is a CRM system; in the worst case our customers would have to deal with angry clients,
and such a thing can result in deaths in aerospace etc.
